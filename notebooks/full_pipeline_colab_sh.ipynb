{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\udec0 Heart Disease \u2014 Full Pipeline (Colab)\n**Feature Engineering v2 \u00b7 Optuna \u00b7 3-Model Ensemble \u00b7 Stacking**\n\n### Before running\n1. Run Cell 1 to install\n2. Run Cell 2 to upload `train_clean.csv` then `test.csv`\n3. Run all remaining cells top to bottom\n- **2-fold CV** to keep runtime short\n- **20 Optuna trials** per model\n- Early stopping handled correctly per model type throughout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 1 \u00b7 Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "!pip install optuna catboost lightgbm --upgrade --quiet\nprint('\u2705 Done')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 2 \u00b7 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings, io\nwarnings.filterwarnings('ignore')\n\nimport optuna\noptuna.logging.set_verbosity(optuna.logging.WARNING)\n\nfrom lightgbm import LGBMClassifier\nfrom lightgbm import early_stopping as lgbm_es, log_evaluation as lgbm_log\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\n\nsns.set_theme(style='whitegrid')\nplt.rcParams['figure.dpi'] = 100\n\n# \u2500\u2500 Global CV config \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nN_FOLDS  = 2   # keep low for Colab stability\nN_TRIALS = 20  # per model\n\nprint('\u2705 Imports done')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 3 \u00b7 Upload Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import files\n\nprint('\ud83d\udcc1 Upload train_clean.csv')\nup = files.upload()\ntrain_bytes = list(up.values())[0]\n\nprint('\ud83d\udcc1 Upload test.csv')\nup = files.upload()\ntest_bytes = list(up.values())[0]\n\ndf   = pd.read_csv(io.BytesIO(train_bytes))\ntest = pd.read_csv(io.BytesIO(test_bytes))\nprint(f'\u2705 Train: {df.shape} | Test: {test.shape}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 4 \u00b7 Groups & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def rebuild_groups(data):\n    d = data.copy()\n    d['sex_label'] = d['Sex'].map({1: 'Male', 0: 'Female'})\n    d['under_surveillance'] = (\n        (d['Number of vessels fluro'] > 0) |\n        (d['Thallium'] == 6) |\n        (d['EKG results'] == 2)\n    ).astype(int)\n    d['group'] = d['sex_label'] + ' / ' + d['under_surveillance'].map({0:'Naive', 1:'Surveilled'})\n    return d\n\ndef engineer_features(data):\n    d = data.copy()\n    # v1 \u2014 interactions\n    d['sex_x_chest_pain']   = d['Sex'] * d['Chest pain type']\n    d['sex_x_slope']        = d['Sex'] * d['Slope of ST']\n    d['sex_x_max_hr']       = d['Sex'] * d['Max HR']\n    d['surv_x_cholesterol'] = d['under_surveillance'] * d['Cholesterol']\n    d['surv_x_max_hr']      = d['under_surveillance'] * d['Max HR']\n    d['surv_x_bp']          = d['under_surveillance'] * d['BP']\n    d['hr_reserve']         = (220 - d['Age']) - d['Max HR']\n    # v2 \u2014 clinical\n    d['thallium_x_vessels'] = d['Thallium'] * d['Number of vessels fluro']\n    d['thallium_x_chest']   = d['Thallium'] * d['Chest pain type']\n    d['thallium_x_angina']  = d['Thallium'] * d['Exercise angina']\n    d['age_bin']            = pd.cut(d['Age'], bins=[0,40,50,60,70,110],\n                                     labels=[0,1,2,3,4]).astype(int)\n    d['risk_score']         = (\n        d['Number of vessels fluro'] * 2 +\n        (d['Thallium'] == 7).astype(int) * 3 +\n        d['Exercise angina'] +\n        (d['ST depression'] > 1).astype(int) +\n        (d['Slope of ST'] == 2).astype(int) * 2\n    )\n    d['st_x_slope']         = d['ST depression'] * d['Slope of ST']\n    d['hr_res_x_angina']    = d['hr_reserve'] * d['Exercise angina']\n    d['age_x_sex']          = d['Age'] * d['Sex']\n    return d\n\ndf   = rebuild_groups(df)\ndf   = engineer_features(df)\ntest = rebuild_groups(test)\ntest = engineer_features(test)\n\nFEATURE_COLS = [c for c in df.columns if c not in\n                ['id', 'target', 'sex_label', 'group', 'Heart Disease', 'sample_weight']]\n\nX      = df[FEATURE_COLS].copy()\ny      = df['target']\ngroups = df['group']\n\nweight_map = {\n    'Female / Naive':      4.0,\n    'Female / Surveilled': 2.0,\n    'Male / Naive':        1.5,\n    'Male / Surveilled':   1.0,\n}\nsample_weights = groups.map(weight_map)\nskf            = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\ngroup_encoded  = pd.Categorical(groups).codes\n\nprint(f'Features: {len(FEATURE_COLS)}')\nprint(df['group'].value_counts())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 5 \u00b7 Fit Helper\nHandles early stopping correctly for each model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def fit_model(model, X_train, y_train, X_val, y_val, w_train, es_rounds=50):\n    \"\"\"Single fit call with correct early stopping per model type.\"\"\"\n    name = type(model).__name__\n    if name == 'LGBMClassifier':\n        model.fit(X_train, y_train,\n                  sample_weight=w_train,\n                  eval_set=[(X_val, y_val)],\n                  callbacks=[lgbm_es(es_rounds, verbose=False), lgbm_log(-1)])\n    elif name == 'XGBClassifier':\n        model.fit(X_train, y_train,\n                  sample_weight=w_train,\n                  eval_set=[(X_val, y_val)],\n                  early_stopping_rounds=es_rounds,\n                  verbose=False)\n    else:  # CatBoost \u2014 od_wait set in constructor\n        model.fit(X_train, y_train,\n                  sample_weight=w_train,\n                  eval_set=[(X_val, y_val)],\n                  verbose=False)\n    return model\n\n\ndef run_cv(model_fn, es_rounds=50):\n    \"\"\"Run N_FOLDS CV, return (mean_auc, fn_rate_female_naive, oof).\"\"\"\n    oof = np.zeros(len(X))\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, group_encoded)):\n        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        w_tr        = sample_weights.iloc[train_idx]\n        model       = model_fn()\n        fit_model(model, X_tr, y_tr, X_val, y_val, w_tr, es_rounds)\n        oof[val_idx] = model.predict_proba(X_val)[:, 1]\n\n    mean_auc = roc_auc_score(y, oof)\n    mask     = groups == 'Female / Naive'\n    yt, yp   = y[mask], (oof[mask] >= 0.5).astype(int)\n    tn, fp, fn, tp = confusion_matrix(yt, yp).ravel()\n    return mean_auc, fn / max(fn + tp, 1), oof\n\n\ndef evaluate_by_group(y_true, y_pred_proba, threshold=0.5):\n    y_pred  = (y_pred_proba >= threshold).astype(int)\n    results = []\n    for group in sorted(groups.unique()):\n        mask = groups == group\n        yt, yp, ypp = y_true[mask], y_pred[mask], y_pred_proba[mask]\n        if yt.nunique() < 2: continue\n        tn, fp, fn, tp = confusion_matrix(yt, yp).ravel()\n        results.append({\n            'group':     group,\n            'n':         int(mask.sum()),\n            'AUC':       round(roc_auc_score(yt, ypp), 4),\n            'Recall':    round(recall_score(yt, yp, zero_division=0), 3),\n            'FN_rate':   round(fn / max(fn + tp, 1), 3),\n        })\n    print(pd.DataFrame(results).set_index('group').to_string())\n\n\n# Optuna patience-based early stopping\nclass OptunaES:\n    def __init__(self, patience=8):\n        self.patience = patience\n        self._best   = -np.inf\n        self._count  = 0\n    def __call__(self, study, trial):\n        best = max((t.values[0] for t in study.best_trials), default=-np.inf)\n        if best > self._best + 1e-5:\n            self._best, self._count = best, 0\n        else:\n            self._count += 1\n        if self._count >= self.patience:\n            print(f'\u23f9 Optuna ES after {self.patience} non-improving trials')\n            study.stop()\n\nprint('\u2705 Helpers ready')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 6 \u00b7 Optuna \u2014 LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def lgbm_objective(trial):\n    model_fn = lambda: LGBMClassifier(\n        n_estimators     = trial.suggest_int('n_estimators', 300, 2000),\n        learning_rate    = trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n        num_leaves       = trial.suggest_int('num_leaves', 31, 255),\n        max_depth        = trial.suggest_int('max_depth', 3, 9),\n        min_child_samples= trial.suggest_int('min_child_samples', 10, 100),\n        subsample        = trial.suggest_float('subsample', 0.5, 1.0),\n        colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        reg_alpha        = trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n        reg_lambda       = trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n        verbose=-1, random_state=42, n_jobs=-1,\n    )\n    auc, fn, _ = run_cv(model_fn)\n    return auc, fn\n\nlgbm_study = optuna.create_study(\n    directions=['maximize', 'minimize'],\n    sampler=optuna.samplers.TPESampler(seed=42),\n    storage='sqlite:////content/lgbm_study.db',\n    study_name='lgbm_v1', load_if_exists=True,\n)\nn_done = len(lgbm_study.trials)\nprint(f'LightGBM: {n_done} done, running {max(0, N_TRIALS-n_done)} more...')\nlgbm_study.optimize(lgbm_objective, n_trials=max(0, N_TRIALS-n_done),\n                    callbacks=[OptunaES(patience=8)], show_progress_bar=True)\nprint(f'\u2705 {len(lgbm_study.best_trials)} Pareto-optimal trials')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 7 \u00b7 Optuna \u2014 XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def xgb_objective(trial):\n    model_fn = lambda: XGBClassifier(\n        n_estimators     = trial.suggest_int('n_estimators', 300, 2000),\n        learning_rate    = trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n        max_depth        = trial.suggest_int('max_depth', 3, 9),\n        subsample        = trial.suggest_float('subsample', 0.5, 1.0),\n        colsample_bytree = trial.suggest_float('colsample_bytree', 0.5, 1.0),\n        min_child_weight = trial.suggest_int('min_child_weight', 1, 20),\n        gamma            = trial.suggest_float('gamma', 0.0, 5.0),\n        reg_alpha        = trial.suggest_float('reg_alpha', 1e-3, 10.0, log=True),\n        reg_lambda       = trial.suggest_float('reg_lambda', 1e-3, 10.0, log=True),\n        eval_metric='auc', verbosity=0, random_state=42, n_jobs=-1,\n    )\n    auc, fn, _ = run_cv(model_fn)\n    return auc, fn\n\nxgb_study = optuna.create_study(\n    directions=['maximize', 'minimize'],\n    sampler=optuna.samplers.TPESampler(seed=42),\n    storage='sqlite:////content/xgb_study.db',\n    study_name='xgboost_v1', load_if_exists=True,\n)\nn_done = len(xgb_study.trials)\nprint(f'XGBoost: {n_done} done, running {max(0, N_TRIALS-n_done)} more...')\nxgb_study.optimize(xgb_objective, n_trials=max(0, N_TRIALS-n_done),\n                   callbacks=[OptunaES(patience=8)], show_progress_bar=True)\nprint(f'\u2705 {len(xgb_study.best_trials)} Pareto-optimal trials')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 8 \u00b7 Optuna \u2014 CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def cat_objective(trial):\n    model_fn = lambda: CatBoostClassifier(\n        iterations          = trial.suggest_int('iterations', 300, 2000),\n        learning_rate       = trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n        depth               = trial.suggest_int('depth', 4, 10),\n        l2_leaf_reg         = trial.suggest_float('l2_leaf_reg', 1.0, 20.0, log=True),\n        bagging_temperature = trial.suggest_float('bagging_temperature', 0.0, 1.0),\n        random_strength     = trial.suggest_float('random_strength', 0.0, 10.0),\n        border_count        = trial.suggest_int('border_count', 32, 255),\n        od_type='Iter', od_wait=50,\n        random_seed=42, verbose=0, thread_count=-1,\n    )\n    auc, fn, _ = run_cv(model_fn)\n    return auc, fn\n\ncat_study = optuna.create_study(\n    directions=['maximize', 'minimize'],\n    sampler=optuna.samplers.TPESampler(seed=42),\n    storage='sqlite:////content/cat_study.db',\n    study_name='catboost_v1', load_if_exists=True,\n)\nn_done = len(cat_study.trials)\nprint(f'CatBoost: {n_done} done, running {max(0, N_TRIALS-n_done)} more...')\ncat_study.optimize(cat_objective, n_trials=max(0, N_TRIALS-n_done),\n                   callbacks=[OptunaES(patience=8)], show_progress_bar=True)\nprint(f'\u2705 {len(cat_study.best_trials)} Pareto-optimal trials')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 9 \u00b7 Pareto Front & Best Trial Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def plot_pareto(study, name, ax):\n    all_auc = [t.values[0] for t in study.trials if t.values and len(t.values)==2]\n    all_fn  = [t.values[1] for t in study.trials if t.values and len(t.values)==2]\n    par_auc = [t.values[0] for t in study.best_trials]\n    par_fn  = [t.values[1] for t in study.best_trials]\n    ax.scatter(all_fn, all_auc, alpha=0.2, color='grey', s=15, label='All')\n    ax.scatter(par_fn, par_auc, color='steelblue', s=50, zorder=5, label='Pareto')\n    ax.set_xlabel('FN Rate Female/Naive (\u2193)')\n    ax.set_ylabel('AUC (\u2191)')\n    ax.set_title(name)\n    ax.legend(fontsize=8)\n\nfig, axes = plt.subplots(1, 3, figsize=(16, 4))\nplot_pareto(lgbm_study, 'LightGBM', axes[0])\nplot_pareto(xgb_study,  'XGBoost',  axes[1])\nplot_pareto(cat_study,  'CatBoost', axes[2])\nplt.suptitle('Pareto Front \u2014 AUC vs Female/Naive FN Rate', fontsize=12)\nplt.tight_layout(); plt.show()\n\ndef best_trial(study, fn_penalty=0.5):\n    best_score, best = -np.inf, None\n    for t in study.best_trials:\n        score = t.values[0] - fn_penalty * t.values[1]\n        if score > best_score:\n            best_score, best = score, t\n    return best\n\nlgbm_best = best_trial(lgbm_study)\nxgb_best  = best_trial(xgb_study)\ncat_best  = best_trial(cat_study)\n\nfor name, b in [('LightGBM', lgbm_best), ('XGBoost', xgb_best), ('CatBoost', cat_best)]:\n    print(f'\\n=== {name} ===')\n    print(f'  AUC: {b.values[0]:.4f}  FN: {b.values[1]:.3f}')\n    print(f'  {b.params}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 10 \u00b7 Retrain & Generate Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "X_test = test[FEATURE_COLS].copy()\n\noof_lgbm = np.zeros(len(X)); test_lgbm = np.zeros(len(X_test))\noof_xgb  = np.zeros(len(X)); test_xgb  = np.zeros(len(X_test))\noof_cat  = np.zeros(len(X)); test_cat  = np.zeros(len(X_test))\n\nretrain_configs = [\n    ('LightGBM',\n     lambda: LGBMClassifier(**lgbm_best.params, verbose=-1, random_state=42, n_jobs=-1),\n     oof_lgbm, test_lgbm),\n    ('XGBoost',\n     lambda: XGBClassifier(**xgb_best.params, eval_metric='auc',\n                           verbosity=0, random_state=42, n_jobs=-1),\n     oof_xgb, test_xgb),\n    ('CatBoost',\n     lambda: CatBoostClassifier(**cat_best.params, od_type='Iter', od_wait=50,\n                                random_seed=42, verbose=0, thread_count=-1),\n     oof_cat, test_cat),\n]\n\nfor name, model_fn, oof_, test_ in retrain_configs:\n    print(f'Retraining {name}...')\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, group_encoded)):\n        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_tr, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        w_tr        = sample_weights.iloc[train_idx]\n        model       = model_fn()\n        fit_model(model, X_tr, y_tr, X_val, y_val, w_tr)\n        oof_[val_idx]  = model.predict_proba(X_val)[:, 1]\n        test_         += model.predict_proba(X_test)[:, 1] / N_FOLDS\n    print(f'  OOF AUC: {roc_auc_score(y, oof_):.4f}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 11 \u00b7 Stacking Meta-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "meta_train = np.column_stack([oof_lgbm, oof_xgb, oof_cat])\nmeta_test  = np.column_stack([test_lgbm, test_xgb, test_cat])\n\nmeta_skf  = StratifiedKFold(n_splits=5, shuffle=True, random_state=99)\noof_meta  = np.zeros(len(X))\ntest_meta = np.zeros(len(X_test))\n\nmeta_model = Pipeline([\n    ('scaler', RobustScaler()),\n    ('clf', LogisticRegression(C=1.0, max_iter=1000, random_state=42)),\n])\n\nfor fold, (tr_idx, val_idx) in enumerate(meta_skf.split(meta_train, y)):\n    meta_model.fit(meta_train[tr_idx], y.iloc[tr_idx])\n    oof_meta[val_idx]  = meta_model.predict_proba(meta_train[val_idx])[:, 1]\n    test_meta         += meta_model.predict_proba(meta_test)[:, 1] / 5\n\nauc_stack = roc_auc_score(y, oof_meta)\nauc_avg   = roc_auc_score(y, (oof_lgbm + oof_xgb + oof_cat) / 3)\nprint(f'Stacking AUC:       {auc_stack:.4f}')\nprint(f'Simple average AUC: {auc_avg:.4f}')\n\nif auc_stack > auc_avg:\n    print('\u2192 Using stacking')\n    final_oof, final_test = oof_meta, test_meta\nelse:\n    print('\u2192 Using simple average')\n    final_oof  = (oof_lgbm + oof_xgb + oof_cat) / 3\n    final_test = (test_lgbm + test_xgb + test_cat) / 3\n\nprint(f'\\nFinal OOF AUC: {roc_auc_score(y, final_oof):.4f}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 12 \u00b7 Per-Group Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print('=== Final Ensemble \u2014 Per-Group ===')\nevaluate_by_group(y, final_oof)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 13 \u00b7 Download Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "from google.colab import files\n\nsubmission = pd.DataFrame({\n    'id':            test['id'],\n    'Heart Disease': final_test,\n})\nsubmission.to_csv('/content/submission_final.csv', index=False)\nprint('\u2705 submission_final.csv ready')\nprint(submission.head())\nprint(submission['Heart Disease'].describe().round(3))\nfiles.download('/content/submission_final.csv')\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  },
  "colab": {
   "provenance": []
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
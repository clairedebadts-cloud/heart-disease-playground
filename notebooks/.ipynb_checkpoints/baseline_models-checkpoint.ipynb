{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\udec0 Heart Disease \u2014 Baseline Models\n",
    "**Group-stratified CV \u00b7 Sex\u00d7Surveillance-aware evaluation \u00b7 Female FN tracking**\n\n",
    "### Pipeline\n",
    "1. Feature engineering (interactions + hr_reserve)\n",
    "2. Group-stratified 5-fold CV (stratify on Sex\u00d7Surveillance)\n",
    "3. LightGBM \u00b7 XGBoost \u00b7 CatBoost \u00b7 Logistic Regression\n",
    "4. Per-group evaluation \u2014 track Female/Naive false negative rate\n",
    "5. Save OOF predictions for ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 1 \u00b7 Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, recall_score, precision_score, confusion_matrix\nfrom sklearn.pipeline import Pipeline\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nsns.set_theme(style='whitegrid')\nplt.rcParams['figure.dpi'] = 120\n\n# \u2500\u2500 Paths \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nBASE = '/users/clairedebadts/kaggle/heart-disease-playground/data/'\ndf   = pd.read_csv(BASE + 'train_clean.csv')\ntest = pd.read_csv(BASE + 'test.csv')\n\nprint(f'Train: {df.shape}  |  Test: {test.shape}')\nprint('Train columns:', df.columns.tolist())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 2 \u00b7 Rebuild Group Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Rebuild group labels \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndf['sex_label'] = df['Sex'].map({1: 'Male', 0: 'Female'})\ndf['under_surveillance'] = (\n    (df['Number of vessels fluro'] > 0) |\n    (df['Thallium'] == 6) |\n    (df['EKG results'] == 2)\n).astype(int)\ndf['group'] = df['sex_label'] + ' / ' + df['under_surveillance'].map({0:'Naive', 1:'Surveilled'})\n\n# Mirror on test\ntest['sex_label'] = test['Sex'].map({1: 'Male', 0: 'Female'})\ntest['under_surveillance'] = (\n    (test['Number of vessels fluro'] > 0) |\n    (test['Thallium'] == 6) |\n    (test['EKG results'] == 2)\n).astype(int)\ntest['group'] = test['sex_label'] + ' / ' + test['under_surveillance'].map({0:'Naive', 1:'Surveilled'})\n\nprint(df['group'].value_counts())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 3 \u00b7 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Feature engineering \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef engineer_features(data):\n    d = data.copy()\n    d['sex_x_chest_pain']   = d['Sex'] * d['Chest pain type']\n    d['sex_x_slope']        = d['Sex'] * d['Slope of ST']\n    d['sex_x_max_hr']       = d['Sex'] * d['Max HR']\n    d['surv_x_cholesterol'] = d['under_surveillance'] * d['Cholesterol']\n    d['surv_x_max_hr']      = d['under_surveillance'] * d['Max HR']\n    d['surv_x_bp']          = d['under_surveillance'] * d['BP']\n    d['hr_reserve']         = (220 - d['Age']) - d['Max HR']\n    return d\n\ndf   = engineer_features(df)\ntest = engineer_features(test)\n\nprint('Features added. New shape:', df.shape)\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 4 \u00b7 Features, Weights & CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Feature cols, X, y, groups, weights \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nFEATURE_COLS = [c for c in df.columns if c not in\n                ['id', 'target', 'sex_label', 'group', 'Heart Disease', 'sample_weight']]\n\nX      = df[FEATURE_COLS].copy()\ny      = df['target']\ngroups = df['group']\n\nweight_map = {\n    'Female / Naive':      4.0,\n    'Female / Surveilled': 2.0,\n    'Male / Naive':        1.5,\n    'Male / Surveilled':   1.0,\n}\nsample_weights = groups.map(weight_map)\n\n# Group-stratified CV\nN_FOLDS      = 5\nskf          = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\ngroup_encoded = pd.Categorical(groups).codes\n\nprint(f'Features ({len(FEATURE_COLS)}): {FEATURE_COLS}')\nprint(f'Sample weight distribution:\\n{sample_weights.value_counts()}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 5 \u00b7 Evaluation Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Evaluation helper \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\ndef evaluate_by_group(y_true, y_pred_proba, groups, threshold=0.5, verbose=True):\n    y_pred  = (y_pred_proba >= threshold).astype(int)\n    results = []\n    for group in sorted(groups.unique()):\n        mask = groups == group\n        yt, yp, ypp = y_true[mask], y_pred[mask], y_pred_proba[mask]\n        if yt.nunique() < 2:\n            continue\n        tn, fp, fn, tp = confusion_matrix(yt, yp).ravel()\n        results.append({\n            'group':      group,\n            'n':          int(mask.sum()),\n            'prevalence': round(yt.mean(), 3),\n            'AUC':        round(roc_auc_score(yt, ypp), 4),\n            'Recall':     round(recall_score(yt, yp, zero_division=0), 3),\n            'Precision':  round(precision_score(yt, yp, zero_division=0), 3),\n            'FN_rate':    round(fn / max(fn + tp, 1), 3),\n        })\n    result_df = pd.DataFrame(results).set_index('group')\n    if verbose:\n        print(result_df.to_string())\n    return result_df\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 6 \u00b7 Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Model definitions \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nmodels = {\n    'LightGBM': LGBMClassifier(\n        n_estimators=1000,\n        learning_rate=0.05,\n        num_leaves=63,\n        min_child_samples=20,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        random_state=42,\n        verbose=-1,\n    ),\n    'XGBoost': XGBClassifier(\n        n_estimators=1000,\n        learning_rate=0.05,\n        max_depth=6,\n        subsample=0.8,\n        colsample_bytree=0.8,\n        eval_metric='auc',\n        random_state=42,\n        verbosity=0,\n    ),\n    'CatBoost': CatBoostClassifier(\n        iterations=1000,\n        learning_rate=0.05,\n        depth=6,\n        random_seed=42,\n        verbose=0,\n    ),\n    'LogisticRegression': Pipeline([\n        ('scaler', RobustScaler()),\n        ('clf', LogisticRegression(max_iter=1000, random_state=42, C=1.0)),\n    ]),\n}\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 7 \u00b7 Cross-Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Cross-validation loop \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nresults_summary = {}\noof_preds       = {}\n\nfor model_name, model in models.items():\n    print(f'\\n{\"=\"*55}')\n    print(f'  {model_name}')\n    print(f'{\"=\"*55}')\n\n    oof       = np.zeros(len(X))\n    fold_aucs = []\n\n    for fold, (train_idx, val_idx) in enumerate(skf.split(X, group_encoded)):\n        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n        w_train        = sample_weights.iloc[train_idx]\n        g_val          = groups.iloc[val_idx]\n\n        if model_name == 'LogisticRegression':\n            model.fit(X_train, y_train, **{'clf__sample_weight': w_train})\n        elif model_name == 'LightGBM':\n            model.fit(X_train, y_train,\n                      sample_weight=w_train,\n                      eval_set=[(X_val, y_val)],\n                      callbacks=[])\n        elif model_name == 'CatBoost':\n            model.fit(X_train, y_train,\n                      sample_weight=w_train,\n                      eval_set=(X_val, y_val),\n                      use_best_model=True)\n        else:  # XGBoost\n            model.fit(X_train, y_train,\n                      sample_weight=w_train,\n                      eval_set=[(X_val, y_val)],\n                      verbose=False)\n\n        val_proba     = model.predict_proba(X_val)[:, 1]\n        oof[val_idx]  = val_proba\n        fold_auc      = roc_auc_score(y_val, val_proba)\n        fold_aucs.append(fold_auc)\n        print(f'  Fold {fold+1}: AUC = {fold_auc:.4f}')\n\n    mean_auc = np.mean(fold_aucs)\n    std_auc  = np.std(fold_aucs)\n    print(f'\\n  CV AUC: {mean_auc:.4f} \u00b1 {std_auc:.4f}')\n    print(f'\\n  Per-group evaluation (OOF, threshold=0.5):')\n    group_results = evaluate_by_group(y, oof, groups, threshold=0.5)\n\n    results_summary[model_name] = {\n        'cv_auc_mean':   mean_auc,\n        'cv_auc_std':    std_auc,\n        'group_results': group_results,\n    }\n    oof_preds[model_name] = oof\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 8 \u00b7 Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Summary table \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nprint('\\n' + '='*55)\nprint('  MODEL COMPARISON SUMMARY')\nprint('='*55)\n\nsummary_df = pd.DataFrame({\n    name: {\n        'CV AUC (mean)':   f\"{v['cv_auc_mean']:.4f}\",\n        'CV AUC (std)':    f\"\u00b1{v['cv_auc_std']:.4f}\",\n        'FN Female/Naive': v['group_results'].loc['Female / Naive', 'FN_rate']\n                           if 'Female / Naive' in v['group_results'].index else 'N/A',\n    }\n    for name, v in results_summary.items()\n}).T\nprint(summary_df.to_string())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 9 \u00b7 Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Visualisation \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\nfig, axes = plt.subplots(1, 2, figsize=(15, 5))\n\n# Left: CV AUC\nauc_data = {name: v['cv_auc_mean'] for name, v in results_summary.items()}\naxes[0].bar(auc_data.keys(), auc_data.values(), color='steelblue', alpha=0.8)\naxes[0].set_ylim(0.75, 1.0)\naxes[0].set_title('CV AUC by Model')\naxes[0].set_ylabel('ROC AUC')\nfor i, (name, val) in enumerate(auc_data.items()):\n    axes[0].text(i, val + 0.002, f'{val:.4f}', ha='center', fontsize=9)\n\n# Right: Female/Naive FN rate\nfn_data = {\n    name: v['group_results'].loc['Female / Naive', 'FN_rate']\n    for name, v in results_summary.items()\n    if 'Female / Naive' in v['group_results'].index\n}\naxes[1].bar(fn_data.keys(), fn_data.values(), color='#E91E63', alpha=0.8)\naxes[1].set_title('False Negative Rate \u2014 Female / Naive\\n(lower is better)')\naxes[1].set_ylabel('FN Rate')\nfor i, (name, val) in enumerate(fn_data.items()):\n    axes[1].text(i, val + 0.005, f'{val:.3f}', ha='center', fontsize=9)\n\nplt.suptitle('Baseline Model Comparison', fontsize=13)\nplt.tight_layout()\nplt.show()\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n## 10 \u00b7 Save OOF Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \u2500\u2500 Save OOF predictions for ensembling \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\noof_df          = pd.DataFrame(oof_preds, index=df.index)\noof_df['target'] = y.values\noof_df['group']  = groups.values\noof_df.to_csv(BASE + 'oof_predictions.csv', index=False)\nprint('\u2705 Saved oof_predictions.csv')\n"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}